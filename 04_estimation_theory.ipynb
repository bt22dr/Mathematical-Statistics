{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 추정이론 \n",
    "\n",
    "연구 대상인 확률변수 X의 확률분포를 $P_\\theta(x), \\theta \\in \\Omega$로 표현하자. 이 경우 모수 $\\theta$는 $\\theta = (\\theta_1, \\theta_2, \\cdots , \\theta_k)$로 표현되는 벡터일 수 있으며(ex. 정규분포의 경우 $\\theta = (\\mu, \\sigma^2)$인 것처럼), $\\Omega$는 모수가 가질 수 있는 값의 집합, 즉 모수공간을 뜻한다. 이제 확률분포 $P_\\theta(x), \\theta \\in \\Omega$로부터 크기가 n인 표본 $X_1, X_2, \\cdots , X_n$을 얻었다고 하자(편의상 $X = X_1, X_2, \\cdots , X_n$로 표기). 이때 우리가 관심이 있는 문제는 확률분포 $P_\\theta(x), \\theta \\in \\Omega$을 특징짓는 모수 $\\theta$ 또는 $\\theta$의 함수인 $g(\\theta)$의 추정이다. \n",
    "\n",
    "$g(\\theta)$의 추정에는 두 가지 방법이 있다. \n",
    "- 점추정(point estimation): 표본에 근거한 통계량 $T(X)=T(X_1, X_2, \\cdots , X_n)$을 사용하여 하나의 값으로 $g(\\theta)$를 추정\n",
    "- 구간추정(interval estimation): 두 개의 통계량 $T_1(X), T_2(X)$을 사용하여 구간 $[T_1(X), T_2(X)]$ 안에 $g(\\theta)$가 포함될 확률을 고려\n",
    "\n",
    "**\\[정의 4.1\\]**  \n",
    "미지의(unknown) 모수를 포함하지 않는 랜덤표본 $X_1, X_2, \\cdots , X_n$의 함수를 통계량(statistic)이라고 한다. 모수 $\\theta$의 함수 $g(\\theta)$를 추정하기 위해 사용되는 통계량 $T(X)=T(X_1, \\cdots , X_n)$을 $g(\\theta)$의 추정량(estimator)이라고 하며, 주어진 표본값 $X_1=x_1, X_2 = x_2, \\cdots, X_n=x_n$을 대입해서 구해진 추정량의 특정값, $T(x)=T(x_1, x_2, \\cdots , x_n)$을 추정값(estimate)이라고 한다. \n",
    "\n",
    "모수 $\\theta$와 구별하기 편리하도록 추정량을 $\\hat{\\theta}$로 표기한다. \n",
    "\n",
    "추정량과 추정값을 예를 들어 설명해보자. $X_1, X_2, \\cdots , X_n$을 $N(\\mu, \\sigma^2)$으로부터 얻은 랜덤표본이라고 하자. 모평균 $\\mu$와 모분산 $\\sigma^2$을 추정하고자 할 때, 표본평균\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = T_1(X_1, X_2, \\cdots , X_n) = \\frac{\\sum_{i=1}^{n}X_i}{n}\n",
    "$$\n",
    "\n",
    "와 표본분산\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = T_2(X_1, X_2, \\cdots , X_n) = \\frac{\\sum_{i=1}^{n} (X_i - \\overline{X}_n)^2}{n-1}\n",
    "$$\n",
    "\n",
    "을 추정량으로 사용할 수 있으며, 표본이 주어졌을 때 그들의 값\n",
    "\n",
    "$$\n",
    "T_1(x_1, x_2, \\cdots , x_n) = \\frac{\\sum_{i=1}^{n}x_i}{n}, \\quad T_2(x_1, x_2, \\cdots , x_n) = \\frac{\\sum_{i=1}^{n} (x_i - \\overline{x}_n)^2}{n-1}\n",
    "$$\n",
    "\n",
    "을 추정값이라고 한다. \n",
    "\n",
    "**용어 정리**  \n",
    "- 통계적 추론(Statistical Inference): 모집단에서 추출한 표본 특성을 분석하여, 모집단에 대한 어떤 미지의 양상 or 특징을 알기 위해 통계학을 이용하여 추측하는 과정\n",
    "  - 추정이론(estimation theory): 표본을 통해 모집단 특성(모수)이 어떠한가에 대해 추측하는 과정\n",
    "  - 검정이론(testing theory): 모집단 실제값이 얼마나 되는가 하는 주장과 관련해서, 표본이 가지고 있는 정보를 이용해 가설이 올바른지 그렇지 않은지 판정하는 과정\n",
    "- (통계적) 추정(Statistical Estimation): \n",
    "    - 모수모형일 때: 표본을 통해 모집단의 모수를 알아내는 과정. 예를 들어 한국인의 평균키가 얼마인가? 자동차 사고날 횟수(포아송분포) 예측 등등...\n",
    "- 모수 모형(Parametric Model): 유한한 개수의 모수를 사용하여 설명이 가능한 분포 (cf. 건수가 몇개 안 될 때는 비모수 모형을 사용하는데, 왜냐하면 표본이 너무 작으면 그 표본이 어떤 확률분포를 따른다고 말할 수 있는 근거가 부족하기 때문)\n",
    "- 모수(Parameter): 모집단 분포의 특성을 규정짓는 척도. ('미지'의 '상수'로 취급) 반면 베이즈통계에서는 모수도 변수로 취급한다.\n",
    "- 점추정(Point Estimation): 표본 통계량을 사용하여 하나의 값으로 모수(나 모수의 함수)를 추정하는 방법\n",
    "- 구간추정(Interval Estimation): 두 개의 표본 통계량을 사용하여 그 두 개의 통계량 구간에 모수가 포함될 확률을 고려하는 방법\n",
    "- 통계량(Statistic): 랜덤표본의 확률변수로 만들어지고 모수를 포함하지 않는 확률변량을 통계량이라고 한다. (확률변수로 취급)\n",
    "- 추정량(Estimator): 모수의 추정을 위해 사용하는 통계량(이나 통계량의 함수) (통계량의 부분집합)\n",
    "- 추정치(Estimate): 주어진 표본값을 대입해서 구해진 추정량의 특정값 (추정량의 원소. 추정량 중에서 실현된 수치값, 상수값)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 추정의 방법\n",
    "\n",
    "모수를 추정하는 방법 중 아래 두 가지를 살펴보자\n",
    "- 적률을 사용하는 방법\n",
    "- 가능도원리(likelihood principle)을 사용하는 방법\n",
    "\n",
    "### 4.1.1 적률추정법\n",
    "\n",
    "적률추정의과정  \n",
    "1. 추정의 대상이 되는 모수들이 몇 개인지 파악한다.\n",
    "2. 모수의 갯수만큼 ${\\mu_j}'={m_j}'$ ($j = 1,2, \\cdots , k$. k: 모수의 갯수)의 등식을 설정한다.\n",
    "3. 연립방정식을 풀어서 모수에 관한 식으로 정리한다.\n",
    "4. 위 연립방정식의 해가 각 모수에 대한 적률추정량(Moment Estimator)이다.\n",
    "\n",
    "### 4.1.2 최대가능도 추정법(Maximum likelihood estimation)\n",
    "\n",
    "확률변수 $X_1, X_2, \\cdots , X_n$의 결합확률밀도함수가 $f(x_1, \\cdots, x_n; \\theta)$라고 하자. 결합확률밀도함수 $f(x_1, \\cdots, x_n; \\theta)$는 고정된 모수 $\\theta$에 대하여 $(x_1, \\cdots, x_n)$의 함수로 사용된다. 그러나 반대로 $f(x_1, \\cdots, x_n; \\theta)$를 관측치 $X_1 = x_1, X_2 = x_2, \\cdots , X_n = x_n$이 주어졌을 때 모수 $\\theta(\\in \\Omega)$의 함수로 생각해 볼 수도 있다. 즉 다음과 같이 \n",
    "\n",
    "$$\n",
    "L(\\theta) = L(\\theta; x_1, x_2, \\cdots , x_n) = f(x_1, x_2, \\cdots , x_n; \\theta)\n",
    "$$\n",
    "\n",
    "로 표기하고 이를 $X_1, X_2, \\cdots , X_n$의 가능도함수(likelihood function)라고 한다. 즉, 가능도함수 $L(\\theta)$는 주어진 자료 $(x_1, x_2, \\cdots , x_n)$에 대하여 그것이 얻어질 가능성을 모수 $\\theta$에 대한 함수로 나타낸 것이라 할 수 있다. \n",
    "\n",
    "참고로 가능도함수는 $\\theta$의 함수이므로 확률밀도함수가 아니라는 점을 유의하자. \n",
    "\n",
    "확률변수 $X_1, X_2, \\cdots , X_n$이 서로 독립이고 $X_i$가 확률밀도함수 $f_i(x_i;\\theta)$를 갖는다고 하면 $X_1, X_2, \\cdots , X_n$의 결합확률밀도함수는 \n",
    "\n",
    "$$\n",
    "\\prod_{i=1}^{n} f_i(x_i;\\theta) = f_1(x_1; \\theta)f_2(x_2; \\theta) \\cdots f_n(x_n; \\theta)\n",
    "$$\n",
    "\n",
    "이며, 가능도함수는\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\theta; x_1, \\cdots , x_n) & = \\prod_{i=1}^{n} f_i(x_i; \\theta) \\\\\n",
    "                             & = f_1(x_1; \\theta)f_2(x_2; \\theta) \\cdots f_n(x_n; \\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "로 나타낼수 있다. 따라서 $X_1, X_2, \\cdots , X_n$이 확률밀도함수 $f(x;\\theta)$로부터의 랜덤표본이라고 하면 $f_i(x_i;\\theta) = f(x_i;\\theta)$이므로, 가능도 함수는\n",
    "\n",
    "$$\n",
    "L(\\theta; x_1, \\cdots , x_n) = \\prod_{i=1}^{n} f(x_i; \\theta)\n",
    "$$\n",
    "\n",
    "가 된다. 이 가능도함수를 최대화하는 통계량을 사용하여 모수를 추정하는 방법을 아래 정의에서 설명한다. \n",
    "\n",
    "**\\[정의 4.2\\]**  \n",
    "랜덤표본의 가능도함수 $L(\\theta;x_1, x_2, \\cdots , x_n)$을 최대화하는 $\\theta$의 값을 $\\hat{\\theta} = \\hat{\\theta}(x_1, x_2, \\cdots , x_n) \\in \\Omega$라고 할 때, $\\hat{\\theta} = \\hat{\\theta}(X_1, X_2, \\cdots , X_n) \\in \\Omega$을 모수 $\\theta$의 최대가능도 추정량(maximum likelihood estimator)이라 한다. \n",
    "\n",
    "이 최대가능도 추정량의 의미는 '실제로 관측된' 자료가 얻어질 확률을 가장 높게 만드는(즉, 주어진 관측값을 가장 잘 설명하는) 가능도함수의 $\\theta$값을 모수 $\\theta$의 추정량으로 삼는 것이다. (이 추정량은 랜덤표본에 대한 확률변수들로 이루어진 함수로 표현된다)\n",
    "\n",
    "예를 들어, $X_1, \\cdots , X_5$가 서로 독립인 베르누이(p) 확률변수라고 하자. 이때 $Y=\\sum_{}^{}X_i$는 $B(5,p)$ 분포를 따르며, Y의 확률밀도함수는 몇가지 다른 p에 대해서 다음과 같이 주어진다.\n",
    "<img src=\"./images/binom_dist_table.png\" style=\"width: 50%;\"/>\n",
    "\n",
    "즉 이 표는 Y, p 평면상에 $\\binom{5}{x}p^x(1-p)^{5-x}$의 값을 그려놓은 3차원 그래프처럼 생각해볼 수 있고, 가능도 함수는 Y=y로 주어졌을 때 모수 p에 대한 함수이므로 Y=3으로 주어지면 위 그림에서 빨간색 음영부분에 해당하며, 이는 Y=3에서 자른 그래프의 단면으로 이해하면 된다. 이 단면 그래프에서는 p=0.6에서 가능도 함수값이 0.34560으로 최대가 되며 따라서 최대가능도 추정값은 0.6이다. \n",
    "\n",
    "그런데 가능도함수 $L(\\theta;x_1, x_2, \\cdots , x_n)$을 최대화하는 $\\theta$의 값을 찾는 문제는 로그가능도함수\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "log L(\\theta; x_1, x_2, \\cdots , x_n) & = log \\prod_{i=1}^{n} f_i(x_i; \\theta) \\\\\n",
    "                                      & = \\sum_{i=1}^{n} log\\ f_i(x_i; \\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "를 최대화하는 $\\theta$의 값을 찾는 것과 같다($\\because$ 로그함수는 단조증가함수). \n",
    "\n",
    "로그가능도함수를 이용하는 이유: 랜덤표본의 가능도함수는 주변 확률밀도합수의 곱으로 표현되는데 여기에 로그를 취하면 합이 되므로 미분 계산도 쉬워지고 컴퓨터에서 연산할 때 안정성도 높아진다. \n",
    "\n",
    "많은 경우 로그가능도함수를 최대화하는 문제는 \n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\theta} log L(\\theta; x_1, x_2, \\cdots , x_n) = 0\n",
    "$$\n",
    "\n",
    "의 해를 구하는 문제로 귀착된다. 물론 위 식을 만족하는 값이 곧 로그가능도함수를 최대화한다는 보장은 없으며, 최대화 여부를 2차 미분 등을 통해 가려야 한다.\n",
    "\n",
    "정규분포로 예를 들어 설명해보자. $X_1, X_2, \\cdots , X_n$을 $N(\\mu, \\sigma^2)$으로 부터 얻은 랜덤표본이라고 하자. 이때 가능도함수는 \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(\\mu, \\sigma^2; x_1, x_2, \\cdots , x_n) & = \\prod_{i=1}^{n} f(x_i; \\mu, \\sigma^2) \\\\\n",
    "                                         & = \\frac{1}{(2\\pi\\sigma^2)^{n/2}} e^{-\\sum_{i=1}^{n}(x_i-\\mu)^2/2\\sigma^2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "이며, 따라서 로그가능도함수는\n",
    "\n",
    "$$\n",
    "log L(\\mu, \\sigma^2; x_1, x_2, \\cdots , x_n) = -{n \\over 2}log(2\\pi\\sigma^2)-\\sum_{i=1}^{n}\\frac{(x_i-\\mu)^2}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "이다. 이 로그가능도함수를 최대화하는 $(\\mu, \\sigma^2)$값은 \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\frac{d}{d\\mu} log L(\\mu, \\sigma^2; x_1, x_2, \\cdots , x_n) = \\sum_{i=1}^{n} \\frac{(x_i-\\mu)}{\\sigma^2} = 0 \\\\\n",
    "& \\frac{d}{d\\sigma^2} log L(\\mu, \\sigma^2; x_1, x_2, \\cdots , x_n) = -\\frac{n}{2\\sigma^2}+\\frac{\\sum_{i=1}^{n}(x_i-\\mu)^2}{2\\sigma^4} = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "의 두 연립방정식의 해를 구하면 된다. 이렇게 구한 최대가능도 추정량은\n",
    "\n",
    "$$\n",
    "(\\hat{\\mu}, \\hat{\\sigma}^2) = \\left ( \\overline{X}_n, \\sum_{i=1}^{n} \\frac{(X_i - \\overline{X}_n)^2}{n} \\right )\n",
    "$$\n",
    "\n",
    "이 된다. \n",
    "\n",
    "**\\[정리 4.1\\]**  \n",
    "최대가능도 추정량의 불변성: $X_1, \\cdots , X_n$을 확률밀도함수 $f(x; \\theta), \\theta \\in \\Omega$를 갖는 분포에서 얻은 랜덤표본이라고 하자. $\\hat{\\theta}_n$이 모수 $\\theta$의 최대가능도 추정량이면, $\\theta$의 함수인 $g(\\theta)$에 대하여, $g(\\hat{\\theta}_n)$이 $g(\\theta)$의 최대가능도 추정량이 된다. \n",
    "\n",
    "위에서 $N(\\mu, \\sigma^2)$으로 부터 얻은 랜덤표본에 대한 $\\sigma^2$의 최대가능도 추정량으로 $\\hat{\\sigma^2}=\\sum_{i=1}^{n} \\frac{(X_i - \\overline{X}_n)^2}{n}$을 구하였다 이제, $g(\\sigma^2)=\\sigma$의 최대가능도 추정량은 불변성에 의하여 $g(\\hat{\\sigma^2})=\\hat{\\sigma}$가 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
